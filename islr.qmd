---
title: "Introduction to Statistcal Learing"
subtitle: "with Applications in R (ISLR) abstracted to Biomarker Discovery and Prediction"
author: "Jeffrey Long"
format: html
editor: visual
---

## A Quarto Experiment

Quarto enables you to weave together content and executable code into a finished document.

ISLR second edition is available for the author in [a free pdf format](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf).

This is my biomarker experiment with Quarto and ISLR.

## History

The Elements of Statistical Learning (ESL, by Hastie, Tibshirani, and Friedman) --- was published in 2001. The authors of ISLR2 (the resource of this experiment) are Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani.

## Contents

1.  Introduction
2.  Statistical Learning
3.  Linear Regression
4.  Classification
5.  Resampling Methods
6.  Linear Model Selection and Regularization
7.  Moving Beyond Linearity
8.  Tree-Based Methods
9.  Support Vector Machines
10. Deep Learning
11. Survival Analysis and Censored Data
12. Unsupervised Learning
13. Multiple Testing

## Introduction

Statistical learning refers to a vast set of tools for understanding data. These tools can be classified as supervised or unsupervised. Broadly speaking, supervised statistical learning involves building a statistical model for pre- dicting, or estimating, an output based on one or more inputs. Problems of this nature occur in fields as diverse as business, medicine, astrophysics, and public policy. With unsupervised statistical learning, there are inputs but no supervising output; nevertheless we can learn relationships and struc- ture from such data.

**The `Wage` data** involves predicting a continuous or quantitative output value. This is often referred to as a regression problem. However, in certain cases we may instead wish to predict a non-numerical value---that is, a categorical or qualitative output.

An example of predicting non-numerical values, such as up/down is explored with **the `Smarket` data** are the Standard & Poor's 500 (S&P) stock index over a 5-year period between 2001 and 2005.

Imagine the first steps of a search for biomarkers in gene expression data. We might have demographic information for a number of patients with an indication. We may wish to understand which types of patients are similar to each other by grouping individuals according to observed characteristics. This is a *clustering* problem. Unlike `Wage` and `Smarket` data, here we are not trying to predict an output variable. We will use **the NCI60 data set** to determine groups or clusters based on 6,830 gene expression measurements for 64 cell lines.

In this particular data set, it turns out that the cell lines correspond to 14 different types of cancer. There is clear evidence that cell lines with the same cancer type tend to be located near each other in clustering methods.

We will use *n* to represent the number of distinct data points, or observations, in our sample. We will let *p* denote the number of variables that are available for use in making predictions. For example, the `Wage` data set consists of 11 variables for 3,000 people, so we have *n* = 3,000 observations and *p* = 11 variables (such as year, age, race, and more). We indicate variable names using the font: `Variable Name`.

We will let $x_{ij}$ represent the value of the *j*th variable for the *i*th observation, where *i* = 1,2,...,*n* and *j* = 1,2,...,*p*. Throughout this experiment, *i* will be used to index the samples or observations (from 1 to *n*) and j will be used to index the variables (from 1 to *p*). We let $\chi$ denote an $n × p$ matrix whose (*i*, *j*)th element is $x_{ij}$ .

The product of **A** and **B** is denoted **AB**. The (*i*,*j*)th element of **AB** is computed by multiplying each element of the *i*th row of **A** by the corresponding element of the *j*th column of **B**. That is, $(AB)_{ij} = \Sigma^d_{k=1} a_{ik}b_{kj}$. As an example,

consider $A = \begin{pmatrix}1 & 2\\3 & 4\end{pmatrix}$ and $B = \begin{pmatrix}5 & 6\\7 & 8\end{pmatrix}$ .

$AB = \begin{pmatrix}1 & 2\\3 & 4\end{pmatrix}\begin{pmatrix}5 & 6\\7 & 8\end{pmatrix} = \begin{pmatrix}1*5+2*7 & 1*6+2*8\\3*5+4*7 & 3*6+4*8\end{pmatrix} = \begin{pmatrix}19 & 22\\43 & 50\end{pmatrix}$

Note that this operation produces an $r × s$ matrix. It is only possible to compute **AB** if the number of columns of **A** is the same as the number of rows of **B**.

```{r}
# install.packages("ISLR2")
library(ISLR2)
packageDescription("ISLR2")

```

The website for ISLR2 is [www.statlearning.com](https://www.statlearning.com/).

## Statistical Learning

The input variables are typically denoted using the symbol X, with a subscript to distinguish them. The inputs go by different names, such as predictors, independent variables, features, or sometimes just variables, and is typically denoted using the symbol Y.

Suppose that we observe a quantitative response Y and p different predictors, X1, X2, ... , Xp. We assume that there is some relationship between Y and X = (X1,X2,...,Xp), which can be written in the very general form

$Y =f(X)+\epsilon$.

Here f is some fixed but unknown function of $X_1, \hdots, X_p$ , and $\epsilon$ is a random error term, which is independent of $X$ and has mean zero. In this formulation, $f$ represents the systematic information that $X$ provides about $Y$ . However, the function $f$ that connects the input variable to the output variable is in general unknown. In this situation one must estimate $f$ based on the observed points. Overall, the errors have approximately mean zero. The function $f$ may involve more than one input variable.

### Why Estimate f?

There are two main reasons that we may wish to estimate f: prediction and inference. We discuss each in turn.

#### Prediction

In many situations, a set of inputs $X$ are readily available, but the output $Y$ cannot be easily obtained. In this setting, since the error term averages to zero, we can predict $Y$ using

$\hat{Y} = f(X)$ ,

where $\hat{f}$ represents our estimate for $f$ , and $\hat{Y}$ represents the resulting prediction for $Y$ . In this setting, $\hat{f}$ is often treated as a *black box*, in the sense that one is not typically concerned with the exact form of $\hat{f}$ , provided that it yields accurate predictions for $Y$ .

The accuracy of $\hat{Y}$ as a prediction for $Y$ depends on two quantities, which we will call the *reducible error* and the *irreducible error*. In general, $\hat{f}$ will not be a perfect estimate for \$f\$, and this inaccuracy will introduce some error. This error is reducible because we can potentially improve the accuracy of $\hat{f}$ by using the most appropriate statistical learning technique to estimate $f$ . However, even if it were possible to form a perfect estimate for $f$ , so that our estimated response took the form $\hat{Y} = f(X)$ , our prediction would still have some error in it! This is because $Y$ is also a function of $\epsilon$ , which, by definition, cannot be predicted using $X$ . Therefore, variability associated with $\epsilon$ also affects the accuracy of our predictions. This is known as the irreducible error, because no matter how well we estimate $f$ , we cannot reduce the error introduced by $\epsilon$ .

#### Inference

We are often interested in understanding the association between $Y$ and $X_1,...,X_p$ . In this situation we wish to estimate $f$ , but our goal is not necessarily to make predictions for $Y$ . Now $\hat{f}$ cannot be treated as a black box, because we need to know its exact form. In this setting, one may be interested in answering the following questions:

• Which predictors are associated with the response? It is often the case that only a small fraction of the available predictors are substantially associated with $Y$ . Identifying the few important predictors among a large set of possible variables can be extremely useful, depending on the application.

• What is the relationship between the response and each predictor? Some predictors may have a positive relationship with $Y$ , in the sense that larger values of the predictor are associated with larger values of $Y$ . Other predictors may have the opposite relationship. Depending on the complexity of $f$ , the relationship between the response and a given predictor may also depend on the values of the other predictors.

• Can the relationship between $Y$ and each predictor be adequately summarized using a linear equation, or is the relationship more complicated? Historically, most methods for estimating $f$ have taken a linear form. In some situations, such an assumption is reasonable or even desirable. But often the true relationship is more complicated, in which case a linear model may not provide an accurate representation of the relationship between the input and output variables.

### How Do We Estimate $f$ ?

Our goal is to apply a statistical learning method to the training data in order to estimate the unknown function $f$ .

-   training data - observations and responses

-   parametric methods - model-based approach that makes an assumption about $f$ i.e. *linear model*, then fits or trains the model i.e. *least squares*. Beware of overfitting.

-   non-parametric - methods do not make explicit assumptions about the functional form of $f$ . Instead they seek an estimate of f that gets as close to the data points as possible without being too rough or wiggly. Such approaches can have a major advantage over parametric approaches: by avoiding the assumption of a particular functional form for $f$ , they have the potential to accurately fit a wider range of possible shapes for $f$ . Any parametric approach brings with it the possibility that the functional form used to estimate $f$ is very different from the true $f$ , in which case the resulting model will not fit the data well. In contrast, non-parametric approaches completely avoid this danger, since essentially no assumption about the form of $f$ is made. But non-parametric approaches do suffer from a major disadvantage: since they do not reduce the problem of estimating $f$ to a small number of parameters, a very large number of observations (far more than is typically needed for a parametric approach) is required in order to obtain an accurate estimate for $f$ .

### The Trade-Off Between Prediction Accuracy and Model Interpretability

Some methods such as linear regression are less flexible, or more restrictive, in the sense that they can produce just a relatively small range of shapes to estimate $f$ , such as linear function. Other methods such as thin plate splines are considerably more flexible because they can generate a much wider range of possible shapes to estimate $f$ .

![A representation of the tradeoff between flexibility and interpretability, using different statistical learning methods. In general, as the flexibility of a method increases, its interpretability decreases.](interpretability_v_flexibility.png)

However, if we are mainly interested in inference, then restrictive models are much more interpretable. For instance, when inference is the goal, the linear model may be a good choice since it will be quite easy to understand the relationship between $Y$ and $X_1,X_2,…,X_p$ .

Least squares linear regression, is relatively inflexible but is quite interpretable. The lasso, relies upon the linear model but uses an alternative fitting procedure for estimating the coefficients $\beta_0, \beta_1, . . . , \beta_p$ . The *lasso* is more restrictive in es- timating the coefficients, and sets a number of them to exactly zero. Hence in this sense the lasso is a less flexible approach than linear regression. It is also more interpretable than linear regression, because in the final model the response variable will only be related to a small subset of the predictors---namely, those with nonzero coefficient estimates. Generalized additive models (GAMs) instead extend the linear model to allow for certain non-linear relationships. Consequently, GAMs are more flexible than linear regression. They are also somewhat less interpretable than linear regression, because the relationship between each predictor and the response is now modeled using a curve. Finally, fully non-linear methods such as bagging, boosting, support vector machines with non-linear kernels, and neural networks (deep learning), are highly flexible approaches that are harder to interpret.

When prediction is the goal, one may suspect the most flexible method is the best choice as it would give the most accurate prediction. However, overfitting often leads us to less flexible methods with improved performance.

### Supervised Versus Unsupervised Learning

In supervised learning problems, for each observation of the predictor measurement(s) $x_i, i = 1, . . . , n$ there is an associated response measurement $y_i$ . We wish to fit a model that relates the response to the predictors, with the aim of accurately predicting the response for future observations (prediction) or better understanding the relationship between the response and the predictors (inference). Many classical statistical learning methods such as linear regression and logistic regression,as well as more modern approaches such as GAM, boosting, and support vector machines, operate in the supervised learning domain.

Unsupervised learning describes the somewhat more challenging situation in which for every observation $i = 1,…,n$ , we observe a vector of measurements $x_i$ but no associated response $y_i$ . It is not possible to fit a linear regression model, since there is no response variable to predict. In this setting, we are in some sense working blind; the situation is referred to as unsupervised because we lack a response variable that can supervise our analysis.

One statistical learning tool that we may use in this setting is cluster analysis, or clustering. The goal of cluster analysis is to ascertain, on the basis of $x_1,…,x_n$ , whether the observations fall into relatively distinct groups. Identifying such groups can be of interest because it might be that the groups differ with respect to some property of interest.

### Regression Versus Classification Problems

Variables can be characterized as either quantitative or qualitative (also known as categorical). Quantitative variables take on numerical values. In contrast, qualitative variables take on values in one of K different classes, or categories. We tend to refer to problems with a quantitative response as regression problems, while those involving a qualitative response are often referred to as classification problems. Least squares linear regression is used with a quantitative response, whereas logistic regression is typically used with a qualitative (two-class, or binary) response. K-nearest neighbors and boosting can be used in the case of either quantitative or qualitative responses.

We tend to select statistical learning methods on the basis of whether the response is quantitative or qualitative. However, whether the predictors are qualitative or quantitative is generally considered less important.

## Assessing Model Accuracy

No one method dominates all others over all possible data sets. Hence it is an important task to decide for any given set of data which method produces the best results. Selecting the best approach can be one of the most challenging parts of performing statistical learning in practice.

### Measuring Quality of Fit

In order to evaluate the performance of a statistical learning method on a given data set, we need some way to measure how well its predictions actually match the observed data. That is, we need to quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation. In the regression setting, the most commonly-used measure is the mean squared error (MSE), given by

$MSE = \frac{1}{n}\Sigma^n_{i=1}(y_i-\hat{f}(x_i))^2$ ,

where $\hat{f}(x_i)$ is the prediction that $\hat{f}$ gives for the $i$th observation.

The MSE will be small if the predicted responses are very close to the true responses, and will be large if for some of the observations, the predicted and true responses differ substantially.

The MSE in is computed using the training data that was used tofit the model, and so should more accurately be referred to as the training MSE. But in general, we do not really care how well the method works training on the training data. Rather, we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data. Suppose that we have clinical measurements (e.g. weight, blood pressure, height, age, family history of disease) for a number of patients, as well as information about whether each patient has diabetes. We can use these patients to train a statistical learning method to predict risk of diabetes based on clinical measurements. In practice, we want this method to accurately predict diabetes risk for future patients based on their clinical measurements. We are not very interested in whether or not the method accurately predicts diabetes risk for patients used to train the model, since we already know which of those patients have diabetes.

We want to choose the method that gives the lowest test MSE, as opposed to the lowest training MSE. If we had a large number of test observations, we could compute

$Ave(y_0 - \hat{f}(x_0))^2$ ,

the average squared prediction error for these test observations $(x_0,y_0)$ . We'd like to select the model for which this quantity is as small as possible.

The degrees of freedom is a quantity that summarizes the flexibility of a curve. When a given method yields a small training MSE but a large test MSE, we are said to be overfitting the data. Regardless of whether or not overfitting has occurred, we almost always expect the training MSE to be smaller than the test MSE because most statistical learning methods either directly or indirectly seek to minimize the training MSE. Overfitting refers specifically to the case in which a less flexible model would have yielded a smaller test MSE.

Plotting of MSE versus degrees of freedom as model flexibility can guide model selection. Cross-validation can estimate the minimum test MSE using the training data.

### The Bias-Variance Trade-Off

It is possible to show that the **expected test MSE**, for a given value $x_0$ , can always be decomposed into the sum of three fundamental quantities: the variance of \$f(x_0)\$, the squared bias of $f(x_0)$ and the variance of the error terms $\epsilon$ .

$E(y_0-\hat{f}(x_0))2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))^2 + Var(\epsilon)$ .

we need to select a statistical learning method that simultaneously achieves low variance and low bias. Note that variance is inherently a nonnegative quantity, and squared bias is also nonnegative. Hence, we see that the expected test MSE can never lie below $Var(\epsilon)$ , the irreducible error.

Variance refers to the amount by which $\hat{f}$ would change if we estimated it using a different training data set. In general, more flexible statistical methods have higher variance. Bias refers to the error that is introduced by approximating a real-life problem, which may be extremely complicated, by a much simpler model. Generally, more flexible methods result in less bias.

As a general rule, as we use more flexible methods, the variance will increase and the bias will decrease. The relative rate of change of these two quantities determines whether the test MSE increases or decreases. As we increase the flexibility of a class of methods, the bias tends to initially decrease faster than the variance increases. Consequently, the expected test MSE declines. However, at some point increasing flexibility has little impact on the bias but starts to significantly increase the variance. When this happens the test MSE increases.
